{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982609f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "\n",
    "import tensorflow as tf \n",
    "import keras \n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6dc774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"datasets/car_price_prediction.csv\")\n",
    "\n",
    "# use prepared dataset\n",
    "df = pd.read_csv(\"../datasets/manipulation/6.csv\")\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46def5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform X/y -split\n",
    "# if you  have more than one independent variables, list them all here\n",
    "# leave out the target variable! (dependent variable)\n",
    "X = df.drop([\"Price\"], axis=1)\n",
    "#X = df.drop(\"Levy\",axis=1)\n",
    "#X = df[['Prod. year', 'Cylinders', 'Airbags']]\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_amount = len(X.columns)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(12, activation=\"relu\", input_shape=(variable_amount,)),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train dtypes:\", X_train.dtypes)\n",
    "print(\"y_train dtype:\", y_train.dtype)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d356884",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7332a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the final model loss/evaluation values\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7cea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# reshape the data for easier comparison table\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "# print the comparison table - true values vs. model predicted values\n",
    "# we can nicely see here how far off our model is in some cases\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35023cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ec990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE - Mean average error\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions), 2), \"$\")\n",
    "\n",
    "# MSE - Mean square error\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2), \"$^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions)), 2), \"$\")\n",
    "\n",
    "# R-squared. 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "# Explained Variance Score => 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "# high variance score = model is a good fit for the data \n",
    "# low variance score = model is not a good fit for the data\n",
    "# the higher the score, the model is more able to explain the variation in the data\n",
    "# if score is low, we might need more and better data\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f13620",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot((y_test - test_predictions))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
